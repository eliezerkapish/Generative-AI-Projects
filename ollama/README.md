## Ollama with LLaMA 3.2

### Overview
This project demonstrates how to set up and test the Ollama framework with the LLaMA 3.2 model. It includes installation instructions, server setup, and running the model.

## Prerequesites
- Ubuntu OS (Tested on Ubuntu Jammy)
- Python 3 installed
- Internet connection for downloading dependencies

## Installation
1.Install required system libraries:
sudo apt-get install -y pciutils
2. Install Ollama:
curl https://ollama.ai/install.sh | sh
